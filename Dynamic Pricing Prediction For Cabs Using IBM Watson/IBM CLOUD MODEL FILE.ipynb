{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020997,
     "end_time": "2021-01-12T04:27:41.230124",
     "exception": false,
     "start_time": "2021-01-12T04:27:41.209127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "***\n",
    "\n",
    "## Lyft/Uber Price Prediction  \n",
    "\n",
    "Given *data about Lyft and Uber rides*, let's try to predict the **price** of a given ride.  \n",
    "  \n",
    "We will use a linear regression model to make our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020362,
     "end_time": "2021-01-12T04:27:41.271130",
     "exception": false,
     "start_time": "2021-01-12T04:27:41.250768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:41.318434Z",
     "iopub.status.busy": "2021-01-12T04:27:41.317711Z",
     "iopub.status.idle": "2021-01-12T04:27:42.430020Z",
     "shell.execute_reply": "2021-01-12T04:27:42.429233Z"
    },
    "papermill": {
     "duration": 1.138714,
     "end_time": "2021-01-12T04:27:42.430156",
     "exception": false,
     "start_time": "2021-01-12T04:27:41.291442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:42.484390Z",
     "iopub.status.busy": "2021-01-12T04:27:42.483603Z",
     "iopub.status.idle": "2021-01-12T04:27:44.932745Z",
     "shell.execute_reply": "2021-01-12T04:27:44.933401Z"
    },
    "papermill": {
     "duration": 2.482487,
     "end_time": "2021-01-12T04:27:44.933541",
     "exception": false,
     "start_time": "2021-01-12T04:27:42.451054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "if os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n",
    "    endpoint_89f17f090d6043c4a4be25f684d2d83b = 'https://s3.us.cloud-object-storage.appdomain.cloud'\n",
    "else:\n",
    "    endpoint_89f17f090d6043c4a4be25f684d2d83b = 'https://s3.private.us.cloud-object-storage.appdomain.cloud'\n",
    "\n",
    "client_89f17f090d6043c4a4be25f684d2d83b = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='Jj0BtmWBaKzFE4gtWoM54zRP4Zs1s7WY5gJvDrCL5iBy',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=endpoint_89f17f090d6043c4a4be25f684d2d83b)\n",
    "\n",
    "body = client_89f17f090d6043c4a4be25f684d2d83b.get_object(Bucket='cabpriceprediction-donotdelete-pr-jy9f0cbn1vendv',Key='cab_rides.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "rides_df = pd.read_csv(body)\n",
    "rides_df.head()\n",
    "body = client_89f17f090d6043c4a4be25f684d2d83b.get_object(Bucket='cabpriceprediction-donotdelete-pr-jy9f0cbn1vendv',Key='weather.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "weather_df = pd.read_csv(body)\n",
    "weather_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:44.999709Z",
     "iopub.status.busy": "2021-01-12T04:27:44.984206Z",
     "iopub.status.idle": "2021-01-12T04:27:45.019281Z",
     "shell.execute_reply": "2021-01-12T04:27:45.019806Z"
    },
    "papermill": {
     "duration": 0.065539,
     "end_time": "2021-01-12T04:27:45.019944",
     "exception": false,
     "start_time": "2021-01-12T04:27:44.954405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:45.068186Z",
     "iopub.status.busy": "2021-01-12T04:27:45.067546Z",
     "iopub.status.idle": "2021-01-12T04:27:45.531722Z",
     "shell.execute_reply": "2021-01-12T04:27:45.530120Z"
    },
    "papermill": {
     "duration": 0.490545,
     "end_time": "2021-01-12T04:27:45.531947",
     "exception": false,
     "start_time": "2021-01-12T04:27:45.041402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:45.584865Z",
     "iopub.status.busy": "2021-01-12T04:27:45.581801Z",
     "iopub.status.idle": "2021-01-12T04:27:45.602220Z",
     "shell.execute_reply": "2021-01-12T04:27:45.602757Z"
    },
    "papermill": {
     "duration": 0.047858,
     "end_time": "2021-01-12T04:27:45.602909",
     "exception": false,
     "start_time": "2021-01-12T04:27:45.555051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:45.666201Z",
     "iopub.status.busy": "2021-01-12T04:27:45.660360Z",
     "iopub.status.idle": "2021-01-12T04:27:45.670218Z",
     "shell.execute_reply": "2021-01-12T04:27:45.671075Z"
    },
    "papermill": {
     "duration": 0.040336,
     "end_time": "2021-01-12T04:27:45.671294",
     "exception": false,
     "start_time": "2021-01-12T04:27:45.630958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022965,
     "end_time": "2021-01-12T04:27:45.718608",
     "exception": false,
     "start_time": "2021-01-12T04:27:45.695643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cleaning Ride Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:45.789457Z",
     "iopub.status.busy": "2021-01-12T04:27:45.769902Z",
     "iopub.status.idle": "2021-01-12T04:27:45.793830Z",
     "shell.execute_reply": "2021-01-12T04:27:45.793163Z"
    },
    "papermill": {
     "duration": 0.051873,
     "end_time": "2021-01-12T04:27:45.793937",
     "exception": false,
     "start_time": "2021-01-12T04:27:45.742064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:46.281942Z",
     "iopub.status.busy": "2021-01-12T04:27:46.281230Z",
     "iopub.status.idle": "2021-01-12T04:27:46.303266Z",
     "shell.execute_reply": "2021-01-12T04:27:46.302729Z"
    },
    "papermill": {
     "duration": 0.485057,
     "end_time": "2021-01-12T04:27:46.303414",
     "exception": false,
     "start_time": "2021-01-12T04:27:45.818357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:46.358894Z",
     "iopub.status.busy": "2021-01-12T04:27:46.358160Z",
     "iopub.status.idle": "2021-01-12T04:27:46.988194Z",
     "shell.execute_reply": "2021-01-12T04:27:46.987497Z"
    },
    "papermill": {
     "duration": 0.659442,
     "end_time": "2021-01-12T04:27:46.988321",
     "exception": false,
     "start_time": "2021-01-12T04:27:46.328879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_df = rides_df.dropna(axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024151,
     "end_time": "2021-01-12T04:27:47.037200",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.013049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cleaning Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:47.098911Z",
     "iopub.status.busy": "2021-01-12T04:27:47.097884Z",
     "iopub.status.idle": "2021-01-12T04:27:47.112324Z",
     "shell.execute_reply": "2021-01-12T04:27:47.112795Z"
    },
    "papermill": {
     "duration": 0.051042,
     "end_time": "2021-01-12T04:27:47.112940",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.061898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:47.170953Z",
     "iopub.status.busy": "2021-01-12T04:27:47.169856Z",
     "iopub.status.idle": "2021-01-12T04:27:47.177463Z",
     "shell.execute_reply": "2021-01-12T04:27:47.176882Z"
    },
    "papermill": {
     "duration": 0.039578,
     "end_time": "2021-01-12T04:27:47.177576",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.137998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:47.235659Z",
     "iopub.status.busy": "2021-01-12T04:27:47.234908Z",
     "iopub.status.idle": "2021-01-12T04:27:47.238208Z",
     "shell.execute_reply": "2021-01-12T04:27:47.237614Z"
    },
    "papermill": {
     "duration": 0.034828,
     "end_time": "2021-01-12T04:27:47.238336",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.203508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_df = weather_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025685,
     "end_time": "2021-01-12T04:27:47.289658",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.263973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating Average Weather DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:47.344663Z",
     "iopub.status.busy": "2021-01-12T04:27:47.343969Z",
     "iopub.status.idle": "2021-01-12T04:27:47.363832Z",
     "shell.execute_reply": "2021-01-12T04:27:47.364506Z"
    },
    "papermill": {
     "duration": 0.049376,
     "end_time": "2021-01-12T04:27:47.364651",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.315275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the timestamp data into real date format\n",
    "rides_df['date'] = pd.to_datetime(rides_df['time_stamp']/ 1000, unit = 's')\n",
    "weather_df['date'] = pd.to_datetime(weather_df['time_stamp'], unit = 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the new column that contain the location and \n",
    "rides_df['merged_date'] = rides_df['source'].astype('str') + ' - ' + rides_df['date'].dt.strftime('%Y-%m-%d').astype('str') + ' - ' + rides_df['date'].dt.hour.astype('str')\n",
    "weather_df['merged_date'] = weather_df['location'].astype('str') + ' - ' + weather_df['date'].dt.strftime('%Y-%m-%d').astype('str') + ' - ' + weather_df['date'].dt.hour.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df_rides['date'].dt.strftime('%m').head()\n",
    "weather_df.index = weather_df['merged_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the weather date on rides data\n",
    "df_joined = rides_df.join(weather_df, on = ['merged_date'], rsuffix ='_w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rides and weather data have been joined by merged_date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined[df_joined['id'] == '865b44b9-4235-4e8e-b6fd-bc8373e95b63'].iloc[:,10:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_group = pd.DataFrame(df_joined.groupby('id')['temp','clouds', 'pressure', 'rain', 'humidity', 'wind'].mean())\n",
    "df_rides_weather = rides_df.join(id_group, on = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the columns for Month, Hour and Weekdays \n",
    "df_rides_weather['Month'] = df_rides_weather['date'].dt.month\n",
    "df_rides_weather['Hour'] = df_rides_weather['date'].dt.hour\n",
    "df_rides_weather['Day'] =  df_rides_weather['date'].dt.strftime('%A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distribution of rides in weekdays \n",
    "import matplotlib.pyplot as plt\n",
    "uber_day_count = df_rides_weather[df_rides_weather['cab_type'] == 'Uber']['Day'].value_counts()\n",
    "uber_day_count = uber_day_count.reindex(index = ['Friday','Saturday','Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday'])\n",
    "lyft_day_count = df_rides_weather[df_rides_weather['cab_type'] == 'Lyft']['Day'].value_counts()\n",
    "lyft_day_count = lyft_day_count.reindex(index = ['Friday','Saturday','Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday'])\n",
    "\n",
    "fig , ax = plt.subplots(figsize = (12,12))\n",
    "ax.plot(uber_day_count.index, uber_day_count, label = 'Uber')\n",
    "ax.plot(lyft_day_count.index, lyft_day_count, label = 'Lyft')\n",
    "ax.set(ylabel = 'Number of Rides', xlabel = 'Weekdays')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ride distribution in one day \n",
    "fig , ax = plt.subplots(figsize= (12,12))\n",
    "ax.plot(df_rides_weather[df_rides_weather['cab_type'] == 'Lyft'].groupby('Hour').Hour.count().index, df_rides_weather[df_rides_weather['cab_type'] == 'Lyft'].groupby('Hour').Hour.count(), label = 'Lyft')\n",
    "ax.plot(df_rides_weather[df_rides_weather['cab_type'] == 'Uber'].groupby('Hour').Hour.count().index, df_rides_weather[df_rides_weather['cab_type'] =='Uber'].groupby('Hour').Hour.count(), label = 'Uber')\n",
    "ax.legend()\n",
    "ax.set(xlabel = 'Hours', ylabel = 'Number of Rides')\n",
    "plt.xticks(range(0,24,1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Average price of rides by type of service\n",
    "import seaborn as sns\n",
    "\n",
    "uber_order =[ 'UberPool', 'UberX', 'UberXL', 'Black','Black SUV','WAV' ]\n",
    "lyft_order = ['Shared', 'Lyft', 'Lyft XL', 'Lux', 'Lux Black', 'Lux Black XL']\n",
    "fig, ax = plt.subplots(2,2, figsize = (20,15))\n",
    "ax1 = sns.barplot(x = df_rides_weather[df_rides_weather['cab_type'] == 'Uber'].name, y = df_rides_weather[df_rides_weather['cab_type'] == 'Uber'].price , ax = ax[0,0], order = uber_order)\n",
    "ax2 = sns.barplot(x = df_rides_weather[df_rides_weather['cab_type'] == 'Lyft'].name, y = df_rides_weather[df_rides_weather['cab_type'] == 'Lyft'].price , ax = ax[0,1], order = lyft_order)\n",
    "ax3 = sns.barplot(x = df_rides_weather[df_rides_weather['cab_type'] == 'Uber'].groupby('name').name.count().index, y = df_rides_weather[df_rides_weather['cab_type'] == 'Uber'].groupby('name').name.count(), ax = ax[1,0] ,order = uber_order)\n",
    "ax4 = sns.barplot(x = df_rides_weather[df_rides_weather['cab_type'] == 'Lyft'].groupby('name').name.count().index, y = df_rides_weather[df_rides_weather['cab_type'] == 'Lyft'].groupby('name').name.count(), ax = ax[1,1],order = lyft_order)\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "ax1.set(xlabel = 'Type of Service', ylabel = 'Average Price')\n",
    "ax2.set(xlabel = 'Type of Service', ylabel = 'Average Price')\n",
    "ax3.set(xlabel = 'Type of Service', ylabel = 'Number of Rides')\n",
    "ax4.set(xlabel = 'Type of Service', ylabel = 'Number of Rides')\n",
    "ax1.set_title('The Uber Average Prices by Type of Service')\n",
    "ax2.set_title('The Lyft Average Prices by Type of Service')\n",
    "ax3.set_title('The Number of Uber Rides by Type of Service')\n",
    "ax4.set_title('The Number of Lyft Rides by Type of Service')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The average price by distance\n",
    "fig , ax = plt.subplots(figsize = (12,12))\n",
    "ax.plot(df_rides_weather[df_rides_weather['cab_type'] == 'Lyft'].groupby('distance').price.mean().index, df_rides_weather[df_rides_weather['cab_type'] == 'Lyft'].groupby('distance')['price'].mean(), label = 'Lyft')\n",
    "ax.plot(df_rides_weather[df_rides_weather['cab_type'] == 'Uber'].groupby('distance').price.mean().index, df_rides_weather[df_rides_weather['cab_type'] =='Uber'].groupby('distance').price.mean(), label = 'Uber')\n",
    "ax.set_title('The Average Price by distance', fontsize= 15)\n",
    "ax.set(xlabel = 'Distance', ylabel = 'Price' )\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The average price by distance \n",
    "fig, ax = plt.subplots(1,2 , figsize = (20,5))\n",
    "for i,col in enumerate(df_rides_weather[df_rides_weather['cab_type'] == 'Uber']['name'].unique()):\n",
    "    ax[0].plot(df_rides_weather[ df_rides_weather['name'] == col].groupby('distance').price.mean().index, df_rides_weather[ df_rides_weather['name'] == col].groupby('distance').price.mean(), label = col)\n",
    "ax[0].set_title('Uber Average Prices by Distance')\n",
    "ax[0].set(xlabel = 'Distance in Mile', ylabel = 'Average price in USD')\n",
    "ax[0].legend()\n",
    "for i,col in enumerate(df_rides_weather[df_rides_weather['cab_type'] == 'Lyft']['name'].unique()):\n",
    "    ax[1].plot(df_rides_weather[ df_rides_weather['name'] == col].groupby('distance').price.mean().index, df_rides_weather[ df_rides_weather['name'] == col].groupby('distance').price.mean(), label = col)\n",
    "ax[1].set(xlabel = 'Distance in Mile', ylabel = 'Average price in USD')\n",
    "ax[1].set_title('Lyft Average Prices by Distance')\n",
    "ax[1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the average rate per mile\n",
    "df_rides_weather['rate_per_mile'] = round((df_rides_weather['price'] / df_rides_weather['distance'] ),2)\n",
    "# The average rate per mile plot\n",
    "fig, ax = plt.subplots(1,2,figsize = (12,5))\n",
    "ax1 = sns.lineplot(x = df_rides_weather.groupby(['distance'])['rate_per_mile'].mean().index, y = df_rides_weather.groupby('distance')['rate_per_mile'].mean(), ax = ax[0])\n",
    "ax2 = sns.lineplot(x = df_rides_weather.groupby(['distance'])['rate_per_mile'].mean().index, y = df_rides_weather.groupby('distance')['rate_per_mile'].mean(), ax = ax[1])\n",
    "plt.xticks(range(0, 10,1))\n",
    "ax1.set(xlabel = 'Distance', ylabel = 'Rate per Mile in USD')\n",
    "ax2.set(xlabel = 'Distance', ylabel = 'Rate per Mile in USD', ylim = (0,15))\n",
    "ax1.set_title('The Average Rate per Mile', fontsize = 16)\n",
    "ax2.set_title('ZOOM Average Rate per Mile', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter chart for Rate per mile and distance\n",
    "    # pivot table to calculate average rate based on cab_type, service type(name) and distance\n",
    "rates_per_mile_pivot = df_rides_weather.pivot_table(index = ['cab_type', 'name', 'distance'] , values = ['rate_per_mile'])\n",
    "rates_per_mile_pivot.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize = (20,8))\n",
    "ax1 = sns.scatterplot(x = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Uber']['distance'], y = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Uber']['rate_per_mile'], hue = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Uber']['name'], ax = ax[0,0])\n",
    "ax2 = sns.scatterplot(x = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Uber']['distance'], y = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Uber']['rate_per_mile'], hue = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Uber']['name'], ax = ax[1,0])\n",
    "ax2.set( ylim = (0,20))\n",
    "ax3 = sns.scatterplot(x = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Lyft']['distance'], y = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Lyft']['rate_per_mile'], hue = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Lyft']['name'], ax = ax[0,1])\n",
    "ax4 = sns.scatterplot(x = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Lyft']['distance'], y = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Lyft']['rate_per_mile'], hue = rates_per_mile_pivot[rates_per_mile_pivot['cab_type'] == 'Lyft']['name'], ax = ax[1,1])\n",
    "ax4.set( ylim = (0,20))\n",
    "handles_uber, labels_uber = ax1.get_legend_handles_labels()\n",
    "handles_uber = [handles_uber[6],handles_uber[3],handles_uber[4],handles_uber[5],handles_uber[1],handles_uber[2]]\n",
    "labels_uber = [labels_uber[6],labels_uber[3],labels_uber[4],labels_uber[5],labels_uber[1],labels_uber[2]]\n",
    "ax1.legend(handles_uber, labels_uber)\n",
    "ax2.legend(handles_uber, labels_uber)\n",
    "handles_lyft, labels_lyft = ax3.get_legend_handles_labels()\n",
    "handles_lyft = [handles_lyft[6],handles_lyft[4],handles_lyft[5],handles_lyft[1],handles_lyft[2],handles_lyft[3]]\n",
    "labels_lyft = [labels_lyft[6],labels_lyft[4],labels_lyft[5],labels_lyft[1],labels_lyft[2],labels_lyft[3]]\n",
    "ax3.legend(handles_lyft, labels_lyft)\n",
    "ax4.legend(handles_lyft, labels_lyft)\n",
    "ax1.set_title('Uber Rate per Mile')\n",
    "ax1.set(ylabel = 'Rate per Mile in USD', xlabel = ' ')\n",
    "ax2.set_title('Uber Rate Zoom(0 to 20 USD)')\n",
    "ax2.set(ylabel = 'Rate per Mile in USD', xlabel = 'Distance')\n",
    "ax3.set_title('Lyft Rate per Mile')\n",
    "ax3.set(ylabel = ' ', xlabel = ' ')\n",
    "ax4.set_title('Lyft Rate Zoom(0 to 20 USD)')\n",
    "ax4.set(ylabel = ' ', xlabel = 'Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overrated rides\n",
    "high_mile_rates = df_rides_weather[df_rides_weather['rate_per_mile'] > 80]\n",
    "# The number of overrated rides by cab type\n",
    "high_mile_rates['cab_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overrated Lyft rides\n",
    "high_mile_rates[high_mile_rates['cab_type'] == 'Lyft'].loc[:,['distance', 'cab_type', 'price', 'surge_multiplier','name', 'rate_per_mile']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overrated Uber Rides\n",
    "high_mile_rates[high_mile_rates['cab_type'] == 'Uber'].loc[:,['distance', 'cab_type', 'price', 'surge_multiplier','name', 'rate_per_mile']].sort_values(by = 'rate_per_mile', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of rides based on service type, distance, and price \n",
    "over_rated_pivot = high_mile_rates[high_mile_rates['cab_type'] == 'Uber'].pivot_table(index = ['name', 'distance', 'price'], values = ['id'], aggfunc = len).rename(columns = {'id' : 'count_rides'})\n",
    "over_rated_pivot.reset_index(inplace =True)\n",
    "over_rated_pivot.sort_values(by = ['count_rides', 'name'], ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the ride distances are very short and the number of rides of one specific service type are very high. So, these are cancellations and their prices.\n",
    "\n",
    "**Cancellation prices by service type**\n",
    "* WAV: 7.0\n",
    "* UberPool: 4.5\n",
    "* UberX: 7.0\n",
    "* UberXL: 8.5\n",
    "* Black: 15.0\n",
    "* Black SUV: 27.5\n",
    "\n",
    "Based on these prices, if you are not ready to go, don't call Black SUV :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:47.421644Z",
     "iopub.status.busy": "2021-01-12T04:27:47.420909Z",
     "iopub.status.idle": "2021-01-12T04:27:47.443077Z",
     "shell.execute_reply": "2021-01-12T04:27:47.443544Z"
    },
    "papermill": {
     "duration": 0.05263,
     "end_time": "2021-01-12T04:27:47.443695",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.391065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#before cells are testing\n",
    "\n",
    "weather_df.groupby('location').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:47.508220Z",
     "iopub.status.busy": "2021-01-12T04:27:47.507035Z",
     "iopub.status.idle": "2021-01-12T04:27:47.530615Z",
     "shell.execute_reply": "2021-01-12T04:27:47.531188Z"
    },
    "papermill": {
     "duration": 0.0601,
     "end_time": "2021-01-12T04:27:47.531456",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.471356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_weather_df = weather_df.groupby('location').mean().reset_index(drop=False)\n",
    "avg_weather_df = avg_weather_df.drop('time_stamp', axis=1)\n",
    "avg_weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027902,
     "end_time": "2021-01-12T04:27:47.588283",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.560381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:47.669576Z",
     "iopub.status.busy": "2021-01-12T04:27:47.668524Z",
     "iopub.status.idle": "2021-01-12T04:27:47.672578Z",
     "shell.execute_reply": "2021-01-12T04:27:47.673079Z"
    },
    "papermill": {
     "duration": 0.056935,
     "end_time": "2021-01-12T04:27:47.673216",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.616281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_df = rides_df.drop('merged_date', axis=1)\n",
    "rides_df = rides_df.drop('date', axis=1)\n",
    "rides_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_df.drop('merged_date', axis=1)\n",
    "weather_df = weather_df.drop('date', axis=1)\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:47.736007Z",
     "iopub.status.busy": "2021-01-12T04:27:47.734665Z",
     "iopub.status.idle": "2021-01-12T04:27:47.753693Z",
     "shell.execute_reply": "2021-01-12T04:27:47.753042Z"
    },
    "papermill": {
     "duration": 0.051654,
     "end_time": "2021-01-12T04:27:47.753802",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.702148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_weather_df = avg_weather_df.rename(\n",
    "    columns={\n",
    "        'location': 'source',\n",
    "        'temp': 'source_temp',\n",
    "        'clouds': 'source_clouds',\n",
    "        'pressure': 'source_pressure',\n",
    "        'rain': 'source_rain',\n",
    "        'humidity': 'source_humidity',\n",
    "        'wind': 'source_wind'\n",
    "    }\n",
    ")\n",
    "\n",
    "source_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:47.832672Z",
     "iopub.status.busy": "2021-01-12T04:27:47.831766Z",
     "iopub.status.idle": "2021-01-12T04:27:47.835183Z",
     "shell.execute_reply": "2021-01-12T04:27:47.835651Z"
    },
    "papermill": {
     "duration": 0.052037,
     "end_time": "2021-01-12T04:27:47.835792",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.783755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "destination_weather_df = avg_weather_df.rename(\n",
    "    columns={\n",
    "        'location': 'destination',\n",
    "        'temp': 'destination_temp',\n",
    "        'clouds': 'destination_clouds',\n",
    "        'pressure': 'destination_pressure',\n",
    "        'rain': 'destination_rain',\n",
    "        'humidity': 'destination_humidity',\n",
    "        'wind': 'destination_wind'\n",
    "    }\n",
    ")\n",
    "\n",
    "destination_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:47.900267Z",
     "iopub.status.busy": "2021-01-12T04:27:47.899643Z",
     "iopub.status.idle": "2021-01-12T04:27:49.271950Z",
     "shell.execute_reply": "2021-01-12T04:27:49.272474Z"
    },
    "papermill": {
     "duration": 1.406361,
     "end_time": "2021-01-12T04:27:49.272612",
     "exception": false,
     "start_time": "2021-01-12T04:27:47.866251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = rides_df\\\n",
    "    .merge(source_weather_df, on='source')\\\n",
    "    .merge(destination_weather_df, on='destination')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = data[\"source\"].value_counts()\n",
    "item_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.destination.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = data[\"destination\"].value_counts()\n",
    "item_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.product_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = data[\"name\"].value_counts()\n",
    "item_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = data[\"product_id\"].value_counts()\n",
    "item_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=data.dtypes[data.dtypes=='O'].index.values\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter as c # return counts\n",
    "for i in cat:\n",
    "    print(\"Column :\",i)\n",
    "    print('count of classes : ',data[i].nunique())\n",
    "    print(c(data[i]))\n",
    "    print('*'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes[data.dtypes!='O'].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any()#it will return true if any columns is having null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum() #used for finding the null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.copy()\n",
    "from sklearn.preprocessing import LabelEncoder #importing the LabelEncoding from sklearn\n",
    "x='*'\n",
    "for i in cat:#looping through all the categorical columns\n",
    "    print(\"LABEL ENCODING OF:\",i)\n",
    "    LE = LabelEncoder()#creating an object of LabelEncoder\n",
    "    print(c(data[i])) #getting the classes values before transformation\n",
    "    data[i] = LE.fit_transform(data[i]) # trannsforming our text classes to numerical values\n",
    "    print(c(data[i])) #getting the classes values after transformation\n",
    "    print(x*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(['price','distance','time_stamp','surge_multiplier','id','source_temp','source_clouds','source_pressure','source_rain','source_humidity','source_wind','destination_temp','destination_clouds','destination_pressure','destination_rain','destination_humidity','destination_wind'],axis=1) #independet features\n",
    "x=pd.DataFrame(x)\n",
    "y = data['price'] #dependent feature\n",
    "y=pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rand=RandomForestRegressor(n_estimators=20,random_state=52,n_jobs=-1,max_depth=4)\n",
    "rand.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm_watson_machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "wml_credentials={\n",
    "    \"url\" :\"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\":\"U_RvQaIg609WWkob25zT3ThvNXjU_mGCbFUbxxmRCSwM\"\n",
    "}\n",
    "client=APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_from_space_name(client,space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_uid = guid_from_space_name(client,'cabmodel')\n",
    "print(\"Space UID = \" + space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.software_specifications.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"default_py3.8\")\n",
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details= client.repository.store_model(model=rand,meta_props={\n",
    "    client.repository.ModelMetaNames.NAME : \"Dynamic Price Prediction for Cabs\",\n",
    "    client.repository.ModelMetaNames.TYPE : \"scikit-learn_0.23\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID : \"software_spec_uid\"\n",
    "})\n",
    "\n",
    "model_id=client.repository.get_model_uid(model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecting the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=rand.predict(x_test)\n",
    "print(ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rand, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "duration": 17.588168,
   "end_time": "2021-01-12T04:27:53.923872",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-12T04:27:36.335704",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
